{"cells":[{"attachments":{},"cell_type":"markdown","id":"k7eulrgaQwYy","metadata":{"id":"k7eulrgaQwYy"},"source":["## Import"]},{"cell_type":"code","execution_count":12,"id":"rBvX-8P2QwYy","metadata":{"ExecuteTime":{"end_time":"2022-07-11T08:41:57.003103Z","start_time":"2022-07-11T08:41:53.892893Z"},"executionInfo":{"elapsed":2132,"status":"ok","timestamp":1683473184964,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"rBvX-8P2QwYy"},"outputs":[],"source":["import os\n","import random\n","import warnings\n","from sklearn.model_selection import train_test_split\n","\n","import librosa\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from tqdm.auto import tqdm\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","\n","from transformers import AutoModelForAudioClassification, Wav2Vec2FeatureExtractor\n","\n","warnings.filterwarnings(action='ignore')\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"]},{"cell_type":"code","execution_count":13,"id":"62923ef4","metadata":{},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","device"]},{"attachments":{},"cell_type":"markdown","id":"kkqHli22QwYy","metadata":{"id":"kkqHli22QwYy"},"source":["## Hyperparameter Setting"]},{"cell_type":"code","execution_count":14,"id":"VtG9mP3RQwYz","metadata":{"ExecuteTime":{"end_time":"2022-07-11T08:41:57.006108Z","start_time":"2022-07-11T08:41:57.004370Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683473187622,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"VtG9mP3RQwYz"},"outputs":[],"source":["CFG = {\n","    'SR':16_000,\n","    'SEED':42,\n","    'BATCH_SIZE':8, # out of Memory가 발생하면 줄여주세요\n","    'TOTAL_BATCH_SIZE':32, # 원하는 batch size\n","    'EPOCHS':5,\n","    'LR':1e-5,\n","}"]},{"cell_type":"code","execution_count":15,"id":"f594ad49","metadata":{},"outputs":[],"source":["MODEL_NAME = \"facebook/wav2vec2-base\""]},{"attachments":{},"cell_type":"markdown","id":"QT7_IBn9QwYz","metadata":{"id":"QT7_IBn9QwYz"},"source":["## Fixed Random-Seed"]},{"cell_type":"code","execution_count":16,"id":"KgyHxME7QwYz","metadata":{"ExecuteTime":{"end_time":"2022-07-11T08:41:57.009050Z","start_time":"2022-07-11T08:41:57.006949Z"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1683473189486,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"KgyHxME7QwYz"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(CFG['SEED']) # Seed 고정"]},{"attachments":{},"cell_type":"markdown","id":"r-3_zmrwQwYz","metadata":{"id":"r-3_zmrwQwYz"},"source":["## Data Pre-Processing"]},{"cell_type":"code","execution_count":17,"id":"BcxV618ZQwYz","metadata":{"ExecuteTime":{"end_time":"2022-07-11T08:41:57.006108Z","start_time":"2022-07-11T08:41:57.004370Z"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683473200939,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"BcxV618ZQwYz"},"outputs":[],"source":["train_df = pd.read_csv('../data/train.csv')"]},{"cell_type":"code","execution_count":18,"id":"51b9bb53","metadata":{},"outputs":[],"source":["train_df, valid_df = train_test_split(train_df, test_size=0.2, random_state=CFG['SEED'])"]},{"cell_type":"code","execution_count":19,"id":"e803fb6c","metadata":{},"outputs":[],"source":["train_df.reset_index(drop=True, inplace=True)\n","valid_df.reset_index(drop=True, inplace=True)"]},{"cell_type":"code","execution_count":20,"id":"5798032a","metadata":{},"outputs":[],"source":["def speech_file_to_array_fn(df):\n","    feature = []\n","    for path in tqdm(df['path']):\n","        path = '../data/'+path[2:]\n","        speech_array, _ = librosa.load(path, sr=CFG['SR'])\n","        feature.append(speech_array)\n","    return feature"]},{"cell_type":"code","execution_count":21,"id":"xUBnp4ciQwYz","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["fca0079f6a714ac7885e1474711d7913","4a9ef407319c43bcb20106c47f0db180","7a0c9eaf1d1e4a56a195dff77a7ed5f9","d5a7c1d85e63402ebd0c36cb6883ab33","55e857853048445b87cea2de151ba035","09436c3ae2a44a8ca51ee1103b963ada","f6d802990a2344db99bf282c663efa5a","bb35a24296ed455a872731cef7333ffb","dc7da92e2f454f79b07c3ca86c3cc9d4","a194d82dd952480387bf1f599a8e52e5","4c356887768a4330ab0b0eec28984484","918b0c55f55f4b799fb41adb002c5f1f","9a823940919d4e068c01e31276740b0f","9fe2d03a06474596b0547d0410da8064","520b45d5f972463da632a32f96c71ee4","911d4b1f888540eb96b8b6a48134f078","53ccb4062ee94e0c84618143ff39ce05","df5b9e6414d449f0961eecec22b16991","790f3379b0364c88ae6bdec739b97248","e5a69cc464fe42f6be81a34ed57b1686","29d20f64d430441ea9364b13dfef101b","e7d3b9b9d1224868988e665b4c677357"]},"executionInfo":{"elapsed":95144,"status":"ok","timestamp":1683473315988,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"xUBnp4ciQwYz","outputId":"4e01c3eb-b83e-47e7-951d-aa148b309c6e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb7d6dabfd5c45deb46d7b980f044ea0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4000 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0bd7da506abe4f5193fd91af7f3222a0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1001 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_x = speech_file_to_array_fn(train_df)\n","valid_x = speech_file_to_array_fn(valid_df)"]},{"cell_type":"code","execution_count":22,"id":"7b9fe61b","metadata":{},"outputs":[],"source":["processor = Wav2Vec2FeatureExtractor.from_pretrained(MODEL_NAME)"]},{"attachments":{},"cell_type":"markdown","id":"2d4e081d","metadata":{},"source":["## DataLoader"]},{"cell_type":"code","execution_count":23,"id":"8b14c17a","metadata":{},"outputs":[],"source":["class CustomDataSet(torch.utils.data.Dataset):\n","    def __init__(self, x, y, processor):\n","        self.x = x\n","        self.y = y\n","        self.processor = processor\n","\n","    def __len__(self):\n","        return len(self.x)\n","\n","    def __getitem__(self, idx):\n","        input_values = self.processor(self.x[idx], sampling_rate=CFG['SR'], return_tensors=\"pt\", padding=True).input_values\n","        if self.y is not None:\n","            return input_values.squeeze(), self.y[idx]\n","        else:\n","            return input_values.squeeze()"]},{"cell_type":"code","execution_count":24,"id":"d0d556ad","metadata":{},"outputs":[],"source":["def collate_fn(batch):\n","    x, y = zip(*batch)\n","    x = pad_sequence([torch.tensor(xi) for xi in x], batch_first=True)\n","    y = pad_sequence([torch.tensor([yi]) for yi in y], batch_first=True)  # Convert scalar targets to 1D tensors\n","    return x, y\n"]},{"cell_type":"code","execution_count":25,"id":"48ed6140","metadata":{},"outputs":[],"source":["def create_data_loader(dataset, batch_size, shuffle, collate_fn, num_workers=0):\n","    return DataLoader(dataset,\n","                      batch_size=batch_size,\n","                      shuffle=shuffle,\n","                      collate_fn=collate_fn,\n","                      num_workers=num_workers\n","                      )\n","\n","train_dataset = CustomDataSet(train_x, train_df['label'], processor)\n","valid_dataset = CustomDataSet(valid_x, valid_df['label'], processor)\n","\n","train_loader = create_data_loader(train_dataset, CFG['BATCH_SIZE'], False, collate_fn, 16)\n","valid_loader = create_data_loader(valid_dataset, CFG['BATCH_SIZE'], False, collate_fn, 16)"]},{"attachments":{},"cell_type":"markdown","id":"ZC7hzMtOQwY0","metadata":{"id":"ZC7hzMtOQwY0"},"source":["## Train"]},{"cell_type":"code","execution_count":26,"id":"8b4eb920","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2ForSequenceClassification: ['quantizer.weight_proj.weight', 'project_hid.bias', 'project_q.weight', 'project_q.bias', 'project_hid.weight', 'quantizer.weight_proj.bias', 'quantizer.codevectors']\n","- This IS expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing Wav2Vec2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.bias', 'projector.weight', 'classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["audio_model = AutoModelForAudioClassification.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":27,"id":"49506934","metadata":{},"outputs":[],"source":["class BaseModel(torch.nn.Module):\n","    def __init__(self):\n","        super(BaseModel, self).__init__()\n","        self.model = audio_model\n","        self.model.classifier = nn.Identity()\n","        self.classifier = nn.Linear(256, 8)\n","\n","    def forward(self, x):\n","        output = self.model(x)\n","        output = self.classifier(output.logits)\n","        return output"]},{"cell_type":"code","execution_count":28,"id":"8c3081e9","metadata":{},"outputs":[],"source":["def validation(model, valid_loader, creterion):\n","    model.eval()\n","    val_loss = []\n","\n","    total, correct = 0, 0\n","    test_loss = 0\n","\n","    with torch.no_grad():\n","        for x, y in tqdm(iter(valid_loader)):\n","            x = x.to(device)\n","            y = y.flatten().to(device)\n","\n","            output = model(x)\n","            loss = creterion(output, y)\n","\n","            val_loss.append(loss.item())\n","\n","            test_loss += loss.item()\n","            _, predicted = torch.max(output, 1)\n","            total += y.size(0)\n","            correct += predicted.eq(y).cpu().sum()\n","\n","    accuracy = correct / total\n","\n","    avg_loss = np.mean(val_loss)\n","\n","    return avg_loss, accuracy"]},{"cell_type":"code","execution_count":29,"id":"1aX-3v6JrpX6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683473315989,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"1aX-3v6JrpX6","outputId":"99876b02-be42-4e2a-8b13-844328b558fe"},"outputs":[],"source":["def train(model, train_loader, valid_loader, optimizer, scheduler):\n","    accumulation_step = int(CFG['TOTAL_BATCH_SIZE'] / CFG['BATCH_SIZE'])\n","    model.to(device)\n","    creterion = nn.CrossEntropyLoss().to(device)\n","\n","    best_model = None\n","    best_acc = 0\n","\n","    for epoch in range(1, CFG['EPOCHS']+1):\n","        train_loss = []\n","        model.train()\n","        for i, (x, y) in enumerate(tqdm(train_loader)):\n","            x = x.to(device)\n","            y = y.flatten().to(device)\n","\n","            optimizer.zero_grad()\n","            \n","            output = model(x)\n","            loss = creterion(output, y)\n","            loss.backward()\n","\n","            if (i+1) % accumulation_step == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","            train_loss.append(loss.item())\n","\n","        avg_loss = np.mean(train_loss)\n","        valid_loss, valid_acc = validation(model, valid_loader, creterion)\n","\n","        if scheduler is not None:\n","            scheduler.step(valid_acc)\n","\n","        if valid_acc > best_acc:\n","            best_acc = valid_acc\n","            best_model = model\n","\n","        print(f'epoch:[{epoch}] train loss:[{avg_loss:.5f}] valid_loss:[{valid_loss:.5f}] valid_acc:[{valid_acc:.5f}]')\n","    \n","    print(f'best_acc:{best_acc:.5f}')\n","\n","    return best_model"]},{"attachments":{},"cell_type":"markdown","id":"c33dd8ed","metadata":{},"source":["## Run"]},{"cell_type":"code","execution_count":30,"id":"14ea3f7b","metadata":{},"outputs":[],"source":["model = BaseModel()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=CFG['LR'])\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n","\n","infer_model = train(model, train_loader, valid_loader, optimizer, scheduler)"]},{"attachments":{},"cell_type":"markdown","id":"Uj-WTX6oQwY0","metadata":{"id":"Uj-WTX6oQwY0"},"source":["## Inference"]},{"cell_type":"code","execution_count":31,"id":"7682a35e","metadata":{},"outputs":[],"source":["test_df = pd.read_csv('../data/test.csv')"]},{"cell_type":"code","execution_count":32,"id":"2d6dac72","metadata":{},"outputs":[],"source":["def collate_fn_test(batch):\n","    x = pad_sequence([torch.tensor(xi) for xi in batch], batch_first=True)\n","    return x"]},{"cell_type":"code","execution_count":33,"id":"bd93b96f","metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4602404481864cb4b06a4d95a61fc78d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1881 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["test_x = speech_file_to_array_fn(test_df)"]},{"cell_type":"code","execution_count":34,"id":"ENCOoU00QwY0","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683473315989,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"ENCOoU00QwY0"},"outputs":[],"source":["test_dataset = CustomDataSet(test_x, y=None, processor=processor)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_test)"]},{"cell_type":"code","execution_count":35,"id":"738067b9","metadata":{},"outputs":[],"source":["def inference(model, test_loader):\n","    model.eval()\n","    preds = []\n","    with torch.no_grad():\n","        for x in tqdm(iter(test_loader)):\n","            x = x.to(device)\n","\n","            output = model(x)\n","            preds += output.argmax(-1).detach().cpu().numpy().tolist()\n","\n","    return preds"]},{"cell_type":"code","execution_count":37,"id":"cf21ca7d","metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1924bbc302424ed58f1161b092935084","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/236 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[37], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#preds, probs = inference(infer_model, test_loader)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m preds, probs \u001b[39m=\u001b[39m inference(model, test_loader)\n","Cell \u001b[0;32mIn[35], line 9\u001b[0m, in \u001b[0;36minference\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tqdm(\u001b[39miter\u001b[39m(test_loader)):\n\u001b[1;32m      7\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 9\u001b[0m     output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     10\u001b[0m     \u001b[39mfor\u001b[39;00m prob \u001b[39min\u001b[39;00m output:\n\u001b[1;32m     11\u001b[0m         sm\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[27], line 9\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m----> 9\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[1;32m     10\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(output\u001b[39m.\u001b[39mlogits)\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1817\u001b[0m, in \u001b[0;36mWav2Vec2ForSequenceClassification.forward\u001b[0;34m(self, input_values, attention_mask, output_attentions, output_hidden_states, return_dict, labels)\u001b[0m\n\u001b[1;32m   1814\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[1;32m   1815\u001b[0m output_hidden_states \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_weighted_layer_sum \u001b[39melse\u001b[39;00m output_hidden_states\n\u001b[0;32m-> 1817\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav2vec2(\n\u001b[1;32m   1818\u001b[0m     input_values,\n\u001b[1;32m   1819\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m   1820\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1821\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1822\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1823\u001b[0m )\n\u001b[1;32m   1825\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_weighted_layer_sum:\n\u001b[1;32m   1826\u001b[0m     hidden_states \u001b[39m=\u001b[39m outputs[_HIDDEN_STATES_START_POSITION]\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:1306\u001b[0m, in \u001b[0;36mWav2Vec2Model.forward\u001b[0;34m(self, input_values, attention_mask, mask_time_indices, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1301\u001b[0m output_hidden_states \u001b[39m=\u001b[39m (\n\u001b[1;32m   1302\u001b[0m     output_hidden_states \u001b[39mif\u001b[39;00m output_hidden_states \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1303\u001b[0m )\n\u001b[1;32m   1304\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1306\u001b[0m extract_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_extractor(input_values)\n\u001b[1;32m   1307\u001b[0m extract_features \u001b[39m=\u001b[39m extract_features\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m   1309\u001b[0m \u001b[39mif\u001b[39;00m attention_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1310\u001b[0m     \u001b[39m# compute reduced attention_mask corresponding to feature vectors\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:453\u001b[0m, in \u001b[0;36mWav2Vec2FeatureEncoder.forward\u001b[0;34m(self, input_values)\u001b[0m\n\u001b[1;32m    448\u001b[0m         hidden_states \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    449\u001b[0m             create_custom_forward(conv_layer),\n\u001b[1;32m    450\u001b[0m             hidden_states,\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    452\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m         hidden_states \u001b[39m=\u001b[39m conv_layer(hidden_states)\n\u001b[1;32m    455\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:353\u001b[0m, in \u001b[0;36mWav2Vec2GroupNormConvLayer.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states):\n\u001b[0;32m--> 353\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(hidden_states)\n\u001b[1;32m    354\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m    355\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n","File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n","\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"]}],"source":["preds = inference(infer_model, test_loader)"]},{"attachments":{},"cell_type":"markdown","id":"5FMPeTISQwY0","metadata":{"id":"5FMPeTISQwY0"},"source":["## Submission"]},{"cell_type":"code","execution_count":null,"id":"AXO-EmaQQwY0","metadata":{"executionInfo":{"elapsed":368,"status":"ok","timestamp":1683473316927,"user":{"displayName":"이승윤","userId":"17995305622900705411"},"user_tz":-540},"id":"AXO-EmaQQwY0"},"outputs":[],"source":["submission = pd.read_csv('../data/sample_submission.csv')\n","submission['label'] = preds\n","submission.to_csv('../baseline_submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"id":"7ecb9dd5","metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false},"widgets":{"application/vnd.jupyter.widget-state+json":{"09436c3ae2a44a8ca51ee1103b963ada":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29d20f64d430441ea9364b13dfef101b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a9ef407319c43bcb20106c47f0db180":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09436c3ae2a44a8ca51ee1103b963ada","placeholder":"​","style":"IPY_MODEL_f6d802990a2344db99bf282c663efa5a","value":"100%"}},"4c356887768a4330ab0b0eec28984484":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"520b45d5f972463da632a32f96c71ee4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_29d20f64d430441ea9364b13dfef101b","placeholder":"​","style":"IPY_MODEL_e7d3b9b9d1224868988e665b4c677357","value":" 1881/1881 [00:24&lt;00:00, 97.61it/s]"}},"53ccb4062ee94e0c84618143ff39ce05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55e857853048445b87cea2de151ba035":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"790f3379b0364c88ae6bdec739b97248":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a0c9eaf1d1e4a56a195dff77a7ed5f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb35a24296ed455a872731cef7333ffb","max":5001,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc7da92e2f454f79b07c3ca86c3cc9d4","value":5001}},"911d4b1f888540eb96b8b6a48134f078":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"918b0c55f55f4b799fb41adb002c5f1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a823940919d4e068c01e31276740b0f","IPY_MODEL_9fe2d03a06474596b0547d0410da8064","IPY_MODEL_520b45d5f972463da632a32f96c71ee4"],"layout":"IPY_MODEL_911d4b1f888540eb96b8b6a48134f078"}},"9a823940919d4e068c01e31276740b0f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53ccb4062ee94e0c84618143ff39ce05","placeholder":"​","style":"IPY_MODEL_df5b9e6414d449f0961eecec22b16991","value":"100%"}},"9fe2d03a06474596b0547d0410da8064":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_790f3379b0364c88ae6bdec739b97248","max":1881,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e5a69cc464fe42f6be81a34ed57b1686","value":1881}},"a194d82dd952480387bf1f599a8e52e5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb35a24296ed455a872731cef7333ffb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5a7c1d85e63402ebd0c36cb6883ab33":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a194d82dd952480387bf1f599a8e52e5","placeholder":"​","style":"IPY_MODEL_4c356887768a4330ab0b0eec28984484","value":" 5001/5001 [01:11&lt;00:00, 106.18it/s]"}},"dc7da92e2f454f79b07c3ca86c3cc9d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df5b9e6414d449f0961eecec22b16991":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5a69cc464fe42f6be81a34ed57b1686":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7d3b9b9d1224868988e665b4c677357":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6d802990a2344db99bf282c663efa5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fca0079f6a714ac7885e1474711d7913":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4a9ef407319c43bcb20106c47f0db180","IPY_MODEL_7a0c9eaf1d1e4a56a195dff77a7ed5f9","IPY_MODEL_d5a7c1d85e63402ebd0c36cb6883ab33"],"layout":"IPY_MODEL_55e857853048445b87cea2de151ba035"}}}}},"nbformat":4,"nbformat_minor":5}
